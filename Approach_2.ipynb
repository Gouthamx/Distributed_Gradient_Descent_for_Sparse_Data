{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cea9e34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    spark.stop()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02ac0a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, FloatType\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"APP_2\") \\\n",
    "    .config(\"spark.driver.memory\", \"8g\") \\\n",
    "    .config(\"spark.executor.memory\", \"8g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"userId\", IntegerType(), True),\n",
    "    StructField(\"movieId\", IntegerType(), True),\n",
    "    StructField(\"rating\", FloatType(), True)\n",
    "])\n",
    "# Read ratings.csv\n",
    "df = spark.read.csv(\"ratings.csv\", header=True, schema = schema).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375f1f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Rows:\", df.count())\n",
    "print(\"Unique users:\", df.select(\"userId\").distinct().count())\n",
    "print(\"Unique Movies:\", df.select(\"movieId\").distinct().count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882bf170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select first n unique users\n",
    "unique_users = df.select(\"userId\").distinct().limit(1000)\n",
    "\n",
    "# Keep only rows from these users\n",
    "df = df.join(unique_users, on=\"userId\", how=\"inner\")\n",
    "\n",
    "df.show(5)\n",
    "print(\"Rows:\", df.count())\n",
    "print(\"Unique users:\", df.select(\"userId\").distinct().count())\n",
    "print(\"Unique Movies:\", df.select(\"movieId\").distinct().count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698693e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users = df.select(\"userId\").distinct().count()\n",
    "n_movies = df.select(\"movieId\").distinct().count()\n",
    "n_ratings = df.count()\n",
    "\n",
    "sparsity = (n_ratings / (n_users * n_movies)) * 100\n",
    "print(f\"Sparsity: {sparsity:.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97398796",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, round as spark_round\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, MinMaxScaler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.functions import vector_to_array\n",
    "\n",
    "user_indexer = StringIndexer(inputCol=\"userId\", outputCol=\"user\")\n",
    "movie_indexer = StringIndexer(inputCol=\"movieId\", outputCol=\"movie\")\n",
    "assembler = VectorAssembler(inputCols=[\"rating\"], outputCol=\"rating_vec\")\n",
    "scaler = MinMaxScaler(inputCol=\"rating_vec\", outputCol=\"rating_scaled\")\n",
    "\n",
    "pipeline = Pipeline(stages=[user_indexer, movie_indexer, assembler, scaler])\n",
    "\n",
    "pipeline_model = pipeline.fit(df)\n",
    "scaled_df = pipeline_model.transform(df)\n",
    "\n",
    "# Flatten vector -> float, then round to 1 decimal\n",
    "scaled_df = scaled_df.withColumn(\n",
    "    \"rating_scaled\",\n",
    "    spark_round(vector_to_array(col(\"rating_scaled\"))[0], 1)\n",
    ")\n",
    "\n",
    "# Keep only necessary columns\n",
    "df_final = scaled_df.select(\"user\", \"movie\", \"rating_scaled\")\n",
    "df_final = df_final.cache()\n",
    "df_final.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56607c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.execution.arrow.enabled\", \"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b25bc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# 80% train, 20% test\n",
    "train_df, test_df = df_final.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "#Converting PySpark DF to Pandas to Tensors\n",
    "train_pd = train_df.toPandas()\n",
    "test_pd = test_df.toPandas()\n",
    "\n",
    "X_train = torch.tensor(train_pd[[\"user\", \"movie\"]].values)\n",
    "y_train = torch.tensor(train_pd[\"rating_scaled\"].values)\n",
    "\n",
    "X_test = torch.tensor(test_pd[[\"user\", \"movie\"]].values)\n",
    "y_test = torch.tensor(test_pd[\"rating_scaled\"].values)\n",
    "\n",
    "print(\"Train count:\", X_train.shape[0])\n",
    "print(\"Train Label:\",y_train.shape[0])\n",
    "print(\"Test count:\", X_test.shape[0])\n",
    "print(\"Test Label:\",y_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75a1dc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "#print(train_dataset[2200])\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b591fbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CollabFiltering(nn.Module):\n",
    "    def __init__(self, n_users, n_movies, emb_dim, hidden, dropout):\n",
    "        super().__init__()\n",
    "        self.user_emb = nn.Embedding(n_users, emb_dim)   \n",
    "        self.movie_emb = nn.Embedding(n_movies, emb_dim)  \n",
    "        self.dropout_emb = 0.4\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(emb_dim * 2, hidden), \n",
    "            nn.BatchNorm1d(hidden),  \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden, 1),  \n",
    "            nn.Sigmoid()  \n",
    "        )\n",
    "\n",
    "    def forward(self,user,movie):\n",
    "        u = F.dropout(self.user_emb(user), p=self.dropout_emb, training=self.training)\n",
    "        m = F.dropout(self.movie_emb(movie), p=self.dropout_emb, training=self.training)\n",
    "        \n",
    "        # Concatenate embeddings (instead of dot product)\n",
    "        x = torch.cat([u, m], dim=1)\n",
    "        \n",
    "        # Pass through MLP\n",
    "        return self.mlp(x).squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c039c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b9be9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adam(parameter, m_state, v_state, t, lr=0.1, beta1=0.9, beta2=0.999, epsilon=1e-8):\n",
    "    # Loop over Tensors in model.parameters()\n",
    "    for p in parameter:\n",
    "        if p.grad is None:\n",
    "            continue\n",
    "\n",
    "        # First Time seeing this parameter\n",
    "        if p not in m_state:\n",
    "            m_state[p] = torch.zeros_like(p)\n",
    "            v_state[p] = torch.zeros_like(p)\n",
    "\n",
    "        g = p.grad\n",
    "        # First moment\n",
    "        m_state[p] = beta1 * m_state[p] + (1 - beta1) * g\n",
    "        # Second moment\n",
    "        v_state[p] = beta2 * v_state[p] + (1 - beta2) * (g * g)\n",
    "\n",
    "        # Bias correction\n",
    "        m_corrected = m_state[p] / (1 - beta1 ** t)\n",
    "        v_corrected = v_state[p] / (1 - beta2 ** t)\n",
    "\n",
    "        # Parameter update (in-place)\n",
    "        p.data -= lr * m_corrected / (torch.sqrt(v_corrected) + epsilon)\n",
    "\n",
    "    return m_state, v_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7725ffc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 | Epoch 1/4\n",
      "Train Loss: 0.0490, Train RMSE: 0.2214\n",
      "Test  Loss: 0.0439, Test  RMSE: 0.2094\n",
      "\n",
      "Model 1 | Epoch 2/4\n",
      "Train Loss: 0.0443, Train RMSE: 0.2106\n",
      "Test  Loss: 0.0413, Test  RMSE: 0.2030\n",
      "\n",
      "Model 1 | Epoch 3/4\n",
      "Train Loss: 0.0428, Train RMSE: 0.2069\n",
      "Test  Loss: 0.0426, Test  RMSE: 0.2065\n",
      "\n",
      "Model 1 | Epoch 4/4\n",
      "Train Loss: 0.0422, Train RMSE: 0.2054\n",
      "Test  Loss: 0.0411, Test  RMSE: 0.2026\n",
      "\n",
      "Model 2 | Epoch 1/4\n",
      "Train Loss: 0.0507, Train RMSE: 0.2251\n",
      "Test  Loss: 0.0469, Test  RMSE: 0.2164\n",
      "\n",
      "Model 2 | Epoch 2/4\n",
      "Train Loss: 0.0465, Train RMSE: 0.2156\n",
      "Test  Loss: 0.0464, Test  RMSE: 0.2155\n",
      "\n",
      "Model 2 | Epoch 3/4\n",
      "Train Loss: 0.0454, Train RMSE: 0.2132\n",
      "Test  Loss: 0.0439, Test  RMSE: 0.2095\n",
      "\n",
      "Model 2 | Epoch 4/4\n",
      "Train Loss: 0.0447, Train RMSE: 0.2115\n",
      "Test  Loss: 0.0435, Test  RMSE: 0.2085\n",
      "\n",
      "Model 3 | Epoch 1/4\n",
      "Train Loss: 0.0508, Train RMSE: 0.2254\n",
      "Test  Loss: 0.0450, Test  RMSE: 0.2120\n",
      "\n",
      "Model 3 | Epoch 2/4\n",
      "Train Loss: 0.0475, Train RMSE: 0.2179\n",
      "Test  Loss: 0.0487, Test  RMSE: 0.2207\n",
      "\n",
      "Model 3 | Epoch 3/4\n",
      "Train Loss: 0.0467, Train RMSE: 0.2162\n",
      "Test  Loss: 0.0446, Test  RMSE: 0.2111\n",
      "\n",
      "Model 3 | Epoch 4/4\n",
      "Train Loss: 0.0464, Train RMSE: 0.2155\n",
      "Test  Loss: 0.0451, Test  RMSE: 0.2123\n",
      "\n",
      "Model 4 | Epoch 1/4\n",
      "Train Loss: 0.0508, Train RMSE: 0.2253\n",
      "Test  Loss: 0.0453, Test  RMSE: 0.2129\n",
      "\n",
      "Model 4 | Epoch 2/4\n",
      "Train Loss: 0.0476, Train RMSE: 0.2182\n",
      "Test  Loss: 0.0440, Test  RMSE: 0.2098\n",
      "\n",
      "Model 4 | Epoch 3/4\n",
      "Train Loss: 0.0467, Train RMSE: 0.2162\n",
      "Test  Loss: 0.0459, Test  RMSE: 0.2141\n",
      "\n",
      "Model 4 | Epoch 4/4\n",
      "Train Loss: 0.0463, Train RMSE: 0.2153\n",
      "Test  Loss: 0.0454, Test  RMSE: 0.2131\n",
      "\n",
      "Model 5 | Epoch 1/4\n",
      "Train Loss: 0.0502, Train RMSE: 0.2240\n",
      "Test  Loss: 0.0460, Test  RMSE: 0.2145\n",
      "\n",
      "Model 5 | Epoch 2/4\n",
      "Train Loss: 0.0463, Train RMSE: 0.2152\n",
      "Test  Loss: 0.0469, Test  RMSE: 0.2165\n",
      "\n",
      "Model 5 | Epoch 3/4\n",
      "Train Loss: 0.0453, Train RMSE: 0.2129\n",
      "Test  Loss: 0.0440, Test  RMSE: 0.2098\n",
      "\n",
      "Model 5 | Epoch 4/4\n",
      "Train Loss: 0.0450, Train RMSE: 0.2121\n",
      "Test  Loss: 0.0437, Test  RMSE: 0.2089\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "all_epoch = []\n",
    "\n",
    "epochs = 4\n",
    "n_models = 5\n",
    "n_users_global = df_final.select(\"user\").distinct().count()\n",
    "n_movies_global = df_final.select(\"movie\").distinct().count()\n",
    "\n",
    "for i in range(1, n_models+1):\n",
    "    model = CollabFiltering(n_users_global, n_movies_global, emb_dim=32, hidden=32, dropout=0.03)\n",
    "    m_state, v_state, t = {}, {}, 0\n",
    "\n",
    "    best_rmse = float(\"inf\")\n",
    "    best_epoch = -1\n",
    "    best_state = None\n",
    "\n",
    "    train_losses_epoch, test_losses_epoch = [], []\n",
    "    train_rmses_epoch, test_rmses_epoch = [], []\n",
    "    epoch_states = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # ---------- Training ----------\n",
    "        model.train()\n",
    "        total_loss, total_sq_error, total_samples = 0,0,0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            preds = model(X_batch[:,0].long(), X_batch[:,1].long()).squeeze()\n",
    "            loss = loss_fn(preds, y_batch.float())\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            t += 1\n",
    "            m_state, v_state = adam(model.parameters(), m_state, v_state, t)\n",
    "            total_loss += loss.item()\n",
    "            total_sq_error += torch.sum((preds - y_batch)**2).item()\n",
    "            total_samples += len(y_batch)\n",
    "        train_loss = total_loss / len(train_loader)\n",
    "        train_rmse = (total_sq_error / total_samples)**0.5\n",
    "\n",
    "        # ---------- Testing ----------\n",
    "        model.eval()\n",
    "        total_loss, total_sq_error, total_samples = 0,0,0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in test_loader:\n",
    "                preds = model(X_batch[:,0].long(), X_batch[:,1].long()).squeeze()\n",
    "                loss = loss_fn(preds, y_batch.float())\n",
    "                total_loss += loss.item()\n",
    "                total_sq_error += torch.sum((preds - y_batch)**2).item()\n",
    "                total_samples += len(y_batch)\n",
    "        test_loss = total_loss / len(test_loader)\n",
    "        test_rmse = (total_sq_error / total_samples)**0.5\n",
    "\n",
    "        # ---------- Print per-epoch summary ----------\n",
    "        print(f\"Model {i} | Epoch {epoch+1}/{epochs}\")\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train RMSE: {train_rmse:.4f}\")\n",
    "        print(f\"Test  Loss: {test_loss:.4f}, Test  RMSE: {test_rmse:.4f}\\n\")\n",
    "\n",
    "        # ---------- Save per-epoch stats ----------\n",
    "        train_losses_epoch.append(train_loss)\n",
    "        test_losses_epoch.append(test_loss)\n",
    "        train_rmses_epoch.append(train_rmse)\n",
    "        test_rmses_epoch.append(test_rmse)\n",
    "        epoch_states.append(copy.deepcopy(model.state_dict()))\n",
    "\n",
    "        if test_rmse < best_rmse:\n",
    "            best_rmse = test_rmse\n",
    "            best_epoch = epoch+1\n",
    "            best_state = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    # ---------- Save model stats ----------\n",
    "    all_epoch.append({\n",
    "        \"id\": i,\n",
    "        \"train_losses\": train_losses_epoch,\n",
    "        \"test_losses\": test_losses_epoch,\n",
    "        \"train_rmses\": train_rmses_epoch,\n",
    "        \"test_rmses\": test_rmses_epoch,\n",
    "        \"epoch_states\": epoch_states,\n",
    "        \"best_epoch\": best_epoch,\n",
    "        \"best_rmse\": best_rmse\n",
    "    })\n",
    "    model.load_state_dict(best_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b57f49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "# Save the Base approach results\n",
    "utils.save_results(\"results/app2_results.pkl\", all_epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a056141b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot RMSE curves for each model\n",
    "for result in all_result:\n",
    "    model_id = result[\"model\"]\n",
    "    train_rmses = result[\"train_rmses\"]\n",
    "    test_rmses = result[\"test_rmses\"]\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(train_rmses, label=\"Train RMSE\")\n",
    "    plt.plot(test_rmses, label=\"Test RMSE\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"RMSE\")\n",
    "    plt.title(f\"RMSE Curve for Model {model_id} (Best Epoch {result['best_epoch']}, RMSE={result['best_rmse']:.4f})\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GDP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
